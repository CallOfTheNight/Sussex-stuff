{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CallOfTheNight/Sussex-stuff/blob/main/NLE2023/NLEassignment2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2S8I2ny-ovS"
      },
      "source": [
        "# NLE Assignment: Sentiment Classification\n",
        "\n",
        "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
        "\n",
        "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
        "\n",
        "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
        "\n",
        "Marking guidelines are provided as a separate document.\n",
        "\n",
        "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1gXQAZas-l9c"
      },
      "outputs": [],
      "source": [
        "# Random seed number\n",
        "\n",
        "candidateno=284246 #this MUST be updated to your candidate number so that you get a unique data sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nk8JTP88A8vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f244db-1496-4ca0-d4db-e51368d501eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "#preliminary imports\n",
        "\n",
        "#set up nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "#for setting up training and testing data\n",
        "import random\n",
        "\n",
        "#useful other tools\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from itertools import zip_longest\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.classify.api import ClassifierI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BHBkzAccCVaZ"
      },
      "outputs": [],
      "source": [
        "#do not change the code in this cell\n",
        "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
        "    \"\"\"\n",
        "    Given corpus generator and ratio:\n",
        "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
        "\n",
        "    :param data: A corpus generator.\n",
        "    :param ratio: The proportion of training documents (default 0.7)\n",
        "    :return: a pair (tuple) of lists where the first element of the\n",
        "            pair is a list of the training data and the second is a list of the test data.\n",
        "    \"\"\"\n",
        "\n",
        "    data = list(data)\n",
        "    n = len(data)\n",
        "    train_indices = random.sample(range(n), int(n * ratio))\n",
        "    test_indices = list(set(range(n)) - set(train_indices))\n",
        "    train = [data[i] for i in train_indices]\n",
        "    test = [data[i] for i in test_indices]\n",
        "    return (train, test)\n",
        "\n",
        "\n",
        "def get_train_test_data():\n",
        "\n",
        "    #get ids of positive and negative movie reviews\n",
        "    pos_review_ids=movie_reviews.fileids('pos')\n",
        "    neg_review_ids=movie_reviews.fileids('neg')\n",
        "\n",
        "    #split positive and negative data into training and testing sets\n",
        "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
        "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
        "    #add labels to the data and concatenate\n",
        "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
        "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
        "\n",
        "    return training, testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3LWwBYICPP"
      },
      "source": [
        "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HJLegkdPFUJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413ec309-7610-4dce-b651-46abfb4dabcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The amount of training data is 1400\n",
            "The amount of testing data is 600\n",
            "The representation of a single data item is below\n",
            "(['since', 'their', 'film', 'debut', 'in', '1984', ...], 'pos')\n"
          ]
        }
      ],
      "source": [
        "#do not change the code in this cell\n",
        "random.seed(candidateno)\n",
        "training_data,testing_data=get_train_test_data()\n",
        "print(\"The amount of training data is {}\".format(len(training_data)))\n",
        "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
        "print(\"The representation of a single data item is below\")\n",
        "print(training_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbTq6eGv2XT2"
      },
      "source": [
        "1)  \n",
        "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
        "\n",
        "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
        "\n",
        "c) **Explain** what you have done and why\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "// TODO 12-11-2023\n",
        "\n",
        "1. In order to generate a list of content words. The first things to do with the data set is to construct a bag-of-words representation for each document in the training and testing sets. It shows frequency of occurrence of each word.\n",
        "\n",
        "- in this step. I use the `FreqDist` function to do this. This function will return the frequency of each word. I loop all the dataset to get every frequency of all the words and save it with the label in a list.\n",
        "\n",
        "2. Then, to get the data set with meaningful words, The things have to do is remove the punctuation and stopwords, it is necessary to do a pre-processing for those words set.\n",
        "\n",
        "- I import a model from corpus which called **stopwords**. This model contain a list with english stopwords. It get things easy because I just compare if the word in my data set are one of the element in that stopwords list. If so just remove it. Then I remove all the word which not fully build by alpha. That would remove the number and poctuation. And Change all the words in lower case.\n",
        "\n",
        "3. The next step is figure out how often each of the word occurs in total in my dataset. It is really important for generate a words list.\n",
        "\n",
        "4. Finally, the word list I will generate for this question will be the 10 most frequency words in this dataset. For generate it. There is a nesseary function will be use below and already be used in the lab previous:\n",
        "\n",
        " `most_frequent_words`:  this function should take THREE arguments: 2 frequency distributions and a natural number, k. It should order words by how much more they occur in one frequency distribution than the other.   It should then return the top k highest scoring words.\n",
        "\n",
        "- Use this function above with different order of args to generate the list which aquire by the question."
      ],
      "metadata": {
        "id": "ua1BF1DyYCoi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gvFu36xZ2XT5"
      },
      "outputs": [],
      "source": [
        "# Step 1: construct a bag-of-words saving in two sets.\n",
        "training_basic=[(FreqDist(wordlist),label) for (wordlist,label) in training_data]\n",
        "testing_basic=[(FreqDist(wordlist),label) for (wordlist,label) in testing_data]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RgePc9hV2XT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd5f716-dcf6-49f1-e003-6c60b59c7506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'tuple'> <class 'nltk.probability.FreqDist'> <class 'str'>\n",
            "(FreqDist({'lebowski': 8, 'dude': 8, 'one': 7, 'big': 5, 'coen': 4, 'films': 4, 'time': 4, 'fargo': 4, 'lot': 4, 'coens': 4, ...}), 'pos')\n"
          ]
        }
      ],
      "source": [
        "# Step 2: pre-processing.\n",
        "\n",
        "# Import the set of stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# ---This function is copy from privious lab work.---\n",
        "# This function receive a wordlist arg, change all the letter to lower case, remove all the punctuation and the word which has not represent to any reviews.\n",
        "def normalise(wordlist):\n",
        "    # lower case the list. In this instance, The word-bag has already lower cased.\n",
        "    lowered=[word.lower() for word in wordlist]\n",
        "    return [word for word in lowered if word.isalpha() and word not in stop]\n",
        "\n",
        "# normalise all the data\n",
        "# ATTENCTION: DO NOT USE THE TESTING DATA\n",
        "training_norm=[(FreqDist(normalise(wordlist)),label) for (wordlist,label) in training_data]\n",
        "testing_norm=[(FreqDist(normalise(wordlist)),label) for (wordlist,label) in testing_data]\n",
        "\n",
        "# print and see if it's working well\n",
        "print(type(training_norm),type(training_norm[0]),type(training_norm[0][0]),type(training_norm[0][1]))\n",
        "print(training_norm[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Calculate Total Frequency\n",
        "\n",
        "# two blank list for store the frequency data\n",
        "pos_freq_dist=FreqDist()\n",
        "neg_freq_dist=FreqDist()\n",
        "\n",
        "# loop every data and collect the frequency in one FreqDist object\n",
        "for reviewDist,label in training_norm:\n",
        "    if label=='pos':\n",
        "        pos_freq_dist+=reviewDist\n",
        "    else:\n",
        "        neg_freq_dist+=reviewDist\n",
        "\n",
        "# Print and see if everything working well\n",
        "pos_freq_dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZKfb6g_sEcn",
        "outputId": "f8480409-fec4-4451-88df-5eb579e83d47"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'film': 3699, 'one': 2113, 'movie': 1706, 'like': 1220, 'story': 885, 'good': 857, 'time': 851, 'also': 842, 'even': 819, 'well': 781, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Generate the word list\n",
        "\n",
        "# ---This function is copy from privious lab---\n",
        "# Receive three args, the list of postive frequency, the list of negetive frequency, and a number k\n",
        "# the important things for this function is the third args k. It means that how many word which have the most frequency would be return.\n",
        "# This function will calculate the difference between two views. So that the normal word such as\"one\" or \"from\" might be removed.\n",
        "# In order to get one view of most frequent word. It should be taken by the first arg and the other for the second arg.\n",
        "def most_frequent_words(posfreq,negfreq,topk):\n",
        "    difference=posfreq-negfreq\n",
        "    sorteddiff=difference.most_common()\n",
        "    justwords=[word for (word,freq) in sorteddiff[:topk]]\n",
        "    return justwords\n",
        "\n",
        "# use the function above to get the two list.\n",
        "pos_most = most_frequent_words(pos_freq_dist,neg_freq_dist,10)\n",
        "neg_most = most_frequent_words(neg_freq_dist,pos_freq_dist,10)\n",
        "\n",
        "# Answer here!\n",
        "print(\"list of positive reviews training data: \",pos_most)\n",
        "print(\"list of negitive reviews training data: \",neg_most)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPNXAWyUyhcg",
        "outputId": "a267f3f0-f344-4d05-ce76-937c42afd038"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list of positive reviews training data:  ['film', 'life', 'also', 'story', 'great', 'best', 'well', 'world', 'many', 'family']\n",
            "list of negitive reviews training data:  ['movie', 'bad', 'plot', 'even', 'could', 'nothing', 'worst', 'script', 'supposed', 'get']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApOQE6vND20"
      },
      "source": [
        "2)\n",
        "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
        "\n",
        "b) **Explain** what you have done.\n",
        "\n",
        "[12.5\\%]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "// TODO 12-11-2023\n",
        "\n",
        "In this code cell, I build a Classifier class extend `ClassifierI` class called `WordListClassifier`.\n",
        "\n",
        "To useing this class. There are two args are needed when init a object of this class, which is `pos` and `neg`. They are the word list for training this classifier.\n",
        "\n",
        "After init the object, Use the function `classify` or `classify_many` to test data. these two function are extends from super class. I only rewrited `classify` function.\n",
        "\n",
        "In classify process, This classifier useing a value called `score` to evaluate which class does the test document belong to.\n",
        "when the word in test document appear in the `pos` or `neg` words list. The score will add or minus at the same time. At the end, this function will  a string \"pos\" or \"neg\" depends on the score is positive or negitive.\n",
        "\n",
        "In the end of this cell, I make a simple test for this class."
      ],
      "metadata": {
        "id": "CpLp1BSWq8Vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BThDMrcmODJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd7a089-b221-4d09-f196-6e14560ec632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'neg',\n",
              " 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from nltk.classify.api import ClassifierI\n",
        "import random\n",
        "\n",
        "# My own word list classifier implements the interface ClassifierI\n",
        "class WordListClassifier(ClassifierI):\n",
        "\n",
        "# init this class with the given word list.\n",
        "# In this case, The word list is the one I generate above.\n",
        "    def __init__(self, pos, neg):\n",
        "        self._pos = pos\n",
        "        self._neg = neg\n",
        "\n",
        "# This function receive a FreqDist object as a arg to evaluate the score\n",
        "# for each word appear in the word list, the score will change depends on it's label\n",
        "# It's return one of two value:\"P\" for positive review or \"N\" for the negitive review.\n",
        "# The return depends on the score this doc get. And if the score is zero, The classifer\n",
        "# would randomly select a value.\n",
        "    def classify(self, doc):\n",
        "\n",
        "        score = 0\n",
        "\n",
        "        for word,value in doc.items():\n",
        "            if word in self._pos:\n",
        "                score+=value\n",
        "            if word in self._neg:\n",
        "                score-=value\n",
        "\n",
        "        if score < 0:\n",
        "          label = \"neg\"\n",
        "        elif score == 0:\n",
        "          label = random.choice([\"neg\",\"pos\"])\n",
        "        else:\n",
        "          label = \"pos\"\n",
        "        return label\n",
        "\n",
        "# define for implements the interface\n",
        "    def labels(self):\n",
        "        return (\"pos\", \"neg\")\n",
        "\n",
        "\n",
        "wordListClassifier = WordListClassifier(pos_most, neg_most)\n",
        "# wordListClassifier.classify(FreqDist(\"This movie is so bad\".split()))\n",
        "wordListClassifier.classify_many(doc for doc,label in testing_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6vK5Vyz2XUF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZdDO_Y92XUH"
      },
      "source": [
        "3)\n",
        "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
        "\n",
        "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
        "\n",
        "[20\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "// TODO\n",
        "\n",
        "In this cell, I get a function called `classifier_evaluate` and a class called `ConfusionMatrix` for evaluate the classifier porformance. And all of them are copy from privious lab work. I just make a slightly change.\n",
        "\n",
        "In the first cell. `classifier_evaluate` function receive two args `cls` and `test_data`.\n",
        "`cls`: the classifier object which you want to evaluate the porformance.\n",
        "`test_data`: the test data which will be use when evaluation.\n",
        "\n",
        "In this function, It just simple compare the the label output by the classifier and the real label. And get the rate of it. that is what we called: accuracy.\n",
        "\n",
        "## Answer for question B:\n",
        "\n",
        "It is not a good idea to evaluate the classifier in terms of its  accuracy. Because in the case of the test data we give for evaluate the accuracy are not half positive half negitive, A really bad classifier who just making every label in the same word might get a higher socre than it should be."
      ],
      "metadata": {
        "id": "WdzTTbkptnEr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1LQc8bsA2XUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346f09af-0953-4f2b-8581-41492fb8e8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.64333\n"
          ]
        }
      ],
      "source": [
        "# Calculate the accuracy\n",
        "def classifier_evaluate(cls, test_data):\n",
        "    '''\n",
        "    cls: an instance of a classifier object which has a classify method which returns \"pos\" or \"neg\"\n",
        "    test_data: a list of pairs where each pair is a FreqDist rep of a doc and its label\n",
        "\n",
        "    returns: float point number which is the accuracy of the classifier on the test data provided\n",
        "    '''\n",
        "    acc = 0\n",
        "    docs,goldstandard=zip(*test_data) #note this neat pythonic way of turning a list of pairs into a pair of lists\n",
        "    #pass all of the docs to the classifier and get back a list of predictions\n",
        "    predictions=cls.classify_many(docs)\n",
        "    #zip the predictions with the goldstandard labels and compare\n",
        "    for prediction,goldlabel in zip(predictions,goldstandard):\n",
        "        if prediction==goldlabel:\n",
        "            acc+=1\n",
        "\n",
        "    # print(\"Acc\",acc,\"length\",(len(test_data)))\n",
        "    return acc / (len(test_data))\n",
        "\n",
        "# Run this function\n",
        "score = classifier_evaluate(WordListClassifier(pos_most,neg_most),testing_norm)\n",
        "print(\"Accuracy: \", round(score,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "// TODO\n",
        "\n",
        "In this cell, we get a class for the precision, recall and F1.\n",
        "\n",
        "In order to evaluate it. we need the label list of a classifier output and the real label.\n",
        "\n",
        "Finally, just call each of the required functions.\n",
        "\n",
        "In the end, a simple test for this class is making."
      ],
      "metadata": {
        "id": "_HaXSsLMwkD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R_i80ceP2XUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc79163-5c6b-4756-8aae-22712699db8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision:  0.60574\n",
            "Recall:  0.77333\n",
            "F1:  0.67936\n"
          ]
        }
      ],
      "source": [
        "# Class for calculate the precision, recall and F1 score\n",
        "class ConfusionMatrix:\n",
        "    def __init__(self,predictions,goldstandard,classes=(\"pos\",\"neg\")):\n",
        "\n",
        "        (self.c1,self.c2)=classes\n",
        "        #self.predictions=predictions\n",
        "        self.TP=0\n",
        "        self.FP=0\n",
        "        self.FN=0\n",
        "        self.TN=0\n",
        "        for p,g in zip(predictions,goldstandard):\n",
        "            if g==self.c1:\n",
        "                if p==self.c1:\n",
        "                    self.TP+=1\n",
        "                else:\n",
        "                    self.FN+=1\n",
        "\n",
        "            elif p==self.c1:\n",
        "                self.FP+=1\n",
        "            else:\n",
        "                self.TN+=1\n",
        "\n",
        "\n",
        "    def precision(self):\n",
        "        p=0\n",
        "        p = self.TP / (self.TP + self.FP)\n",
        "\n",
        "        return p\n",
        "\n",
        "    def recall(self):\n",
        "        r=0\n",
        "        r = self.TP / (self.TP + self.FN)\n",
        "\n",
        "        return r\n",
        "\n",
        "    def f1(self):\n",
        "        f1=0\n",
        "        p=self.precision()\n",
        "        r=self.recall()\n",
        "        f1=(p * r * 2) / (p + r)\n",
        "        return f1\n",
        "\n",
        "# Test for this class\n",
        "docs,labels = zip(*testing_norm)\n",
        "cfm = ConfusionMatrix(WordListClassifier(pos_most,neg_most).classify_many(docs),labels)\n",
        "# print(cfm.TP)\n",
        "# print(cfm.FP)\n",
        "# print(cfm.TN)\n",
        "# print(cfm.FN)\n",
        "\n",
        "print(\"Precision: \", round(cfm.precision(),5))\n",
        "print(\"Recall: \", round(cfm.recall(),5))\n",
        "print(\"F1: \", round(cfm.f1(),5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIS9UpmJNEAp"
      },
      "source": [
        "4)\n",
        "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
        "\n",
        "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results.\n",
        "\n",
        "[12.5\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "// TODO\n",
        "\n",
        "Naive Bayes classifier is not a very difficult classifier, Even most of the code was implemented in previous labs. One difference is that the classifier is trained at initialization.\n",
        "\n",
        "In addition, based on the characteristics of naive Bayes, we have three problems to solve, the first is some data that only appears in the test set but not in the training set. These data are not recognized by the classifier. So they're just \"redundant.\" In the code below, I use the \"_set_known_vocabulary\" function to move all words that meet the above criteria out of the classification process.\n",
        "\n",
        "In addition, for some words with a frequency of 0, the classifier cannot recognize them properly, which will result in a multiplier of 0 when calculating the probability, resulting in the entire result being 0. We used a method called \"Laplacian smoothing\" or \"+1 smoothing \"to solve this problem, specifically, for each word, add 1 to its frequency. This eliminates all words with zero occurrences. To make the classifier work properly.\n",
        "\n",
        "The final problem is the loss of precision. When the classifier needs to operate on too many elements, the probability of each element will become small, and the classifier needs to multiply all the small probabilities, which will lead to a very small value, in the computer, when a value is small to a certain extent may lose precision, which will lead to classification errors. Therefore, when we calculate the probability, we add a log to both sides of the equation. This avoids the underflow problem. And the result is the same as the theoretical result without the log.\n",
        "\n",
        "In the end, There is a simple test codes for my NBClassifier."
      ],
      "metadata": {
        "id": "12w8Mfv4yZwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Gwjig-Y12XUN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0138efd0-9ed6-4f1b-f7b7-25a87dc63c11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# for the log function.\n",
        "import math\n",
        "\n",
        "# Naive Bayes Classifier\n",
        "class NBClassifier(ClassifierI):\n",
        "\n",
        "  def __init__(self,training_data):\n",
        "    # pass\n",
        "    self.td = training_data\n",
        "    # known = self._set_known_vocabulary(self.td)\n",
        "    # priors = self._set_priors(self.td)\n",
        "    # c_probs = self._set_cond_probs(self.td)\n",
        "\n",
        "  def _set_known_vocabulary(self,training_data):\n",
        "    known=set()\n",
        "    for doc,label in training_data:\n",
        "        for word in list(doc.keys()):\n",
        "          known.add(word)\n",
        "    return known\n",
        "\n",
        "\n",
        "  def _set_priors(self,training_data):\n",
        "    priors={}\n",
        "\n",
        "    for (doc,label) in training_data:\n",
        "        priors[label]=priors.get(label,0)+1\n",
        "\n",
        "    total=sum(priors.values())\n",
        "\n",
        "    for key,value in priors.items():\n",
        "        priors[key]=value/total\n",
        "\n",
        "    return priors\n",
        "\n",
        "  def _set_cond_probs(self,training_data):\n",
        "    conds={}\n",
        "    for(doc,label) in training_data:\n",
        "        classcond=conds.get(label,{})\n",
        "        for word,value in doc.items():\n",
        "            classcond[word]=classcond.get(word,0)+value\n",
        "\n",
        "        conds[label]=classcond\n",
        "\n",
        "    vocab=self._set_known_vocabulary(training_data)\n",
        "    for label, classcond in conds.items():\n",
        "        for word in vocab:\n",
        "\n",
        "            classcond[word]=classcond.get(word,0)+1\n",
        "        conds[label]=classcond\n",
        "\n",
        "    for label,dist in conds.items():\n",
        "        total=sum(dist.values())\n",
        "        conds[label]={key:value/total for (key,value) in dist.items()}\n",
        "\n",
        "    return conds\n",
        "\n",
        "\n",
        "  # def train(self,training_data):\n",
        "  #     self._set_known_vocabulary(training_data)\n",
        "  #     self._set_priors(training_data)\n",
        "  #     self._set_cond_probs(training_data)\n",
        "\n",
        "  def classify(self,doc):\n",
        "\n",
        "    known = self._set_known_vocabulary(self.td)\n",
        "    priors = self._set_priors(self.td)\n",
        "    c_probs = self._set_cond_probs(self.td)\n",
        "\n",
        "    doc_probs={key:math.log(value) for (key,value) in priors.items()}\n",
        "\n",
        "    for word in doc.keys():\n",
        "        # print(word)\n",
        "        if word in known:\n",
        "          doc_probs={classlabel:sofar+math.log(c_probs[classlabel].get(word,0)) for (classlabel,sofar) in doc_probs.items()}\n",
        "          # print(doc_probs)\n",
        "    highprob=max(doc_probs.values())\n",
        "    # print(doc_probs.values(),doc_probs.keys())\n",
        "    classes=[c for c in doc_probs.keys() if doc_probs[c]==highprob]\n",
        "    # print(classes)\n",
        "    return random.choice(classes)\n",
        "\n",
        "nbdemo = NBClassifier(training_norm)\n",
        "sent = \"movie great bad terrible\"\n",
        "doc = FreqDist(sent.split())\n",
        "nbdemo.classify(doc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I just invoke the code already implemented in the above problem to complete the problem. I generate four metrics for both classifiers to evaluate their performance. It is obvious that naive Bayes classifier perform slightly better than words list classifier.\n",
        "\n",
        "However, the correct choice of classifier still depends on different situations. For example, in the case of performance shortage, the hardware computing power of naive Bayes classifier is much larger than that of word list classifier. This can be perceived simply by calculating the rating speed of the two classifiers from the colab."
      ],
      "metadata": {
        "id": "WDvzLXnI6F47"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3AUsYRMa2XUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f62801-cab0-48da-aae0-ecd2d29d0da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My word list classifier:\n",
            "Acc:  0.68\n",
            "Precision:  1.0\n",
            "Recall:  0.7\n",
            "F1:  0.82353\n",
            "====================\n",
            "NB classifier: \n",
            "Acc:  0.78\n",
            "Precision:  1.0\n",
            "Recall:  0.78\n",
            "F1:  0.8764\n"
          ]
        }
      ],
      "source": [
        "\n",
        "docs,labels = zip(*testing_norm)\n",
        "cfm = ConfusionMatrix(WordListClassifier(pos_most,neg_most).classify_many(docs[:50]),labels)\n",
        "\n",
        "print(\"My word list classifier:\")\n",
        "print(\"Acc: \",classifier_evaluate(wordListClassifier,testing_norm[:50]))\n",
        "print(\"Precision: \", round(cfm.precision(),5))\n",
        "print(\"Recall: \", round(cfm.recall(),5))\n",
        "print(\"F1: \", round(cfm.f1(),5))\n",
        "\n",
        "\n",
        "cfm = ConfusionMatrix(NBClassifier(training_norm).classify_many(docs[:50]),labels)\n",
        "print(\"=\" * 20)\n",
        "print(\"NB classifier: \")\n",
        "print(\"Acc: \",classifier_evaluate(nbdemo,testing_norm[:50]))\n",
        "print(\"Precision: \", round(cfm.precision(),5))\n",
        "print(\"Recall: \", round(cfm.recall(),5))\n",
        "print(\"F1: \", round(cfm.f1(),5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGDXaVDqOSfY"
      },
      "source": [
        "5)\n",
        "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions.\n",
        "\n",
        "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
        "\n",
        "[25\\%]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlxoUthX2XUP"
      },
      "source": [
        "My experiment is very simple, I use a loop to increase the number of words in the word list classifier, where the words will increase from 10 to 1000 with 50 steps. With each addition, its performance is evaluated. The results are stored in a dictionary and displayed with images.\n",
        "\n",
        "According to my experimental results, for word list classifiers, when the number of words increases from very few (about 10) to around 100-150 (for the current training set and test set size). The performance of the classifier is gradually increasing. Then, as the number of words continued to increase, there was a significant fluctuation in performance. I think this is due to overfitting. After about 600+ words, the performance of the classifier starts to flatten out and remains at a stable value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "T1L7mZ-k2XUQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "41b375f5-bfd4-4ab5-f070-8b2546ecd276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{10: {'Acc:': 0.6366666666666667}, 60: {'Acc:': 0.6633333333333333}, 110: {'Acc:': 0.6866666666666666}, 160: {'Acc:': 0.6616666666666666}, 210: {'Acc:': 0.6816666666666666}, 260: {'Acc:': 0.6616666666666666}, 310: {'Acc:': 0.6683333333333333}, 360: {'Acc:': 0.6616666666666666}, 410: {'Acc:': 0.6483333333333333}, 460: {'Acc:': 0.6616666666666666}, 510: {'Acc:': 0.655}, 560: {'Acc:': 0.65}, 610: {'Acc:': 0.6633333333333333}, 660: {'Acc:': 0.67}, 710: {'Acc:': 0.6633333333333333}, 760: {'Acc:': 0.6633333333333333}, 810: {'Acc:': 0.6566666666666666}, 860: {'Acc:': 0.65}, 910: {'Acc:': 0.6566666666666666}, 960: {'Acc:': 0.655}}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Sample Size')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# model for image\n",
        "import pandas as pd\n",
        "\n",
        "# dictionary for saving evaluate score data\n",
        "acc = {}\n",
        "\n",
        "for topk in range(10,1001,50):\n",
        "\n",
        "\n",
        "  # generate a word list classifier object with different size of words lists.\n",
        "  pos_most = most_frequent_words(pos_freq_dist,neg_freq_dist,topk)\n",
        "  neg_most = most_frequent_words(neg_freq_dist,pos_freq_dist,topk)\n",
        "  testWordListClassifier = WordListClassifier(pos_most,neg_most)\n",
        "\n",
        "  temp = classifier_evaluate(testWordListClassifier,testing_norm)\n",
        "  acc[topk] = {\"Acc:\":temp}\n",
        "\n",
        "# print(acc)\n",
        "\n",
        "# =======================================\n",
        "# Draw image\n",
        "df=pd.DataFrame(acc)\n",
        "df=df.transpose()\n",
        "\n",
        "ax = df.plot(kind=\"line\",title=\"Experimental Results\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.set_ybound(0.4,0.8)\n",
        "ax.set_xlabel(\"Sample Size\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34rdlS_iPov6",
        "outputId": "67304ebb-0889-4956-b6ff-97bda763f070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Submission length is 327\n"
          ]
        }
      ],
      "source": [
        "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
        "\n",
        "import io\n",
        "from nbformat import current\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "filepath=\"/content/drive/MyDrive/Colab Notebooks/NLEassignment2023.ipynb\"\n",
        "question_count=432\n",
        "\n",
        "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
        "    nb = current.read(f, 'json')\n",
        "\n",
        "word_count = 0\n",
        "for cell in nb.worksheets[0].cells:\n",
        "    if cell.cell_type == \"markdown\":\n",
        "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
        "print(\"Submission length is {}\".format(word_count-question_count))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}